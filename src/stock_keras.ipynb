{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "running stock_cnn.py ['./train.py', 'WMT', 'original']\n",
      "../stock_history/WMT\n",
      "../outputs/fresh_rolling_train\n",
      "../stock_history/WMT/WMT.csv\n",
      "1 ) 26-04-2021 14_30_05 MainThread INFO\\ Initialized logging at path ../outputs/fresh_rolling_train/logs/log_WMT_original_fresh_rolling_train_26-04-2021_14_30_05.log\n",
      "Tensorflow devices \n",
      "path to company data: ../stock_history/WMT/WMT.csv\n",
      "2 ) 26-04-2021 14_30_05 MainThread DEBUG\\ Data for WMT ready to use\n",
      "3 ) 26-04-2021 14_30_05 MainThread DEBUG\\ Technical indicators already calculated. Loading...\n",
      "4 ) 26-04-2021 14_30_05 MainThread DEBUG\\ Dropped 26 nan rows before label calculation\n",
      "5 ) 26-04-2021 14_30_05 MainThread DEBUG\\ creating label with original paper strategy\n",
      "Calculating labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81637f58ee74da49879d9bbb6915a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5007.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6 ) 26-04-2021 14_30_23 MainThread DEBUG\\ Dropped 10 nan rows after label calculation\n",
      "7 ) 26-04-2021 14_30_26 MainThread DEBUG\\ Number of Technical indicator columns for train/test are 443\n",
      "8 ) 26-04-2021 14_30_29 MainThread DEBUG\\ common selected featues:303, ['rsv_9', 'cmf_21', 'cmf_16', 'kst_6', 'rsi_16', 'mfi_13', 'wr_17', 'cci_22', 'wr_13', 'cmf_25', 'hma_10', 'trix_12', 'cci_16', 'rsi_6', 'rsi_13', 'rsv_20', 'roc_12', 'wr_19', 'mfi_6', 'fi_15', 'kst_8', 'roc_14', 'rsi_18', 'roc_20', 'cmo_13', 'cci_26', 'dpo_20', 'cmo_19', 'rsi_14', 'rsv_21', 'kst_19', 'hma_14', 'cmf_20', 'kdjk_14', 'mfi_22', 'fi_25', 'kst_17', 'mfi_25', 'trix_7', 'kst_23', 'kst_16', 'fi_20', 'eom_22', 'rsv_18', 'high', 'cci_9', 'mfi_20', 'eom_11', 'rsi_9', 'fi_17', 'fi_23', 'eom_9', 'dpo_12', 'rsv_24', 'cci_18', 'kst_24', 'cci_8', 'kdjk_13', 'kdjk_9', 'kdjk_16', 'wr_9', 'mfi_8', 'dpo_11', 'fi_6', 'kst_15', 'cmf_6', 'kdjk_11', 'eom_20', 'cmo_23', 'mfi_14', 'cmo_7', 'roc_15', 'kst_11', 'cmf_12', 'rsv_10', 'wr_8', 'hma_16', 'kst_7', 'eom_18', 'rsi_10', 'cmf_23', 'trix_6', 'hma_11', 'mfi_23', 'cci_20', 'rsv_19', 'adjusted_close', 'rsv_16', 'rsv_26', 'cmf_7', 'cci_15', 'eom_26', 'cmo_20', 'rsi_8', 'cmo_25', 'cci_21', 'kst_21', 'fi_16', 'dpo_26', 'hma_0', 'kdjk_7', 'kdjk_19', 'roc_6', 'roc_16', 'cmo_22', 'roc_18', 'eom_15', 'dpo_10', 'dpo_14', 'kst_18', 'hma_3', 'eom_6', 'mfi_15', 'dpo_15', 'hma_9', 'fi_13', 'fi_22', 'cmf_17', 'mfi_16', 'wr_7', 'kst_10', 'roc_11', 'rsv_23', 'fi_18', 'dpo_18', 'eom_17', 'eom_21', 'rsi_22', 'roc_24', 'fi_11', 'rsi_7', 'kdjk_20', 'dpo_6', 'eom_25', 'rsv_7', 'ema_7', 'rsi_12', 'rsi_23', 'cmo_18', 'dpo_7', 'rsi_11', 'wr_26', 'cmo_24', 'trix_15', 'dpo_22', 'eom_10', 'mfi_24', 'rsv_8', 'cmo_10', 'fi_12', 'cmf_15', 'cmf_22', 'wma_8', 'wr_11', 'dpo_8', 'kdjk_23', 'cmo_16', 'rsv_22', 'cmo_11', 'fi_26', 'wr_18', 'roc_22', 'cmf_11', 'rsv_13', 'eom_23', 'cci_7', 'cmf_9', 'dpo_19', 'fi_7', 'eom_12', 'wr_21', 'wr_12', 'wr_10', 'mfi_10', 'eom_7', 'wr_25', 'fi_10', 'rsi_26', 'kst_20', 'rsv_11', 'eom_24', 'cmf_26', 'cci_14', 'dpo_9', 'rsi_21', 'cci_13', 'cmf_14', 'wr_20', 'cci_11', 'fi_9', 'dpo_23', 'cmo_14', 'mfi_26', 'rsi_17', 'dpo_13', 'rsv_12', 'dpo_16', 'roc_26', 'wma_7', 'bb_6', 'kdjk_15', 'volume', 'mfi_12', 'cmf_18', 'cmf_8', 'cmo_9', 'cmo_26', 'close', 'rsi_24', 'roc_7', 'bb_7', 'kdjk_22', 'cmf_10', 'dpo_25', 'kdjk_10', 'roc_10', 'wma_6', 'kdjk_25', 'roc_9', 'kst_13', 'kdjk_17', 'rsi_25', 'roc_23', 'mfi_21', 'low', 'roc_8', 'cci_19', 'bb_10', 'cmo_21', 'open', 'rsv_14', 'dpo_21', 'roc_25', 'wr_15', 'fi_21', 'cmf_13', 'cci_6', 'kdjk_6', 'dpo_24', 'eom_19', 'rsi_19', 'rsv_6', 'kst_25', 'eom_8', 'fi_8', 'fi_19', 'roc_13', 'mfi_17', 'cci_25', 'kst_22', 'cmf_19', 'mfi_11', 'roc_17', 'trix_16', 'cci_24', 'kst_26', 'wr_14', 'hma_12', 'wr_16', 'cci_12', 'kdjk_18', 'cmo_8', 'rsv_25', 'rsi_20', 'cmo_6', 'mfi_7', 'eom_16', 'cci_10', 'fi_14', 'kst_9', 'eom_14', 'cci_17', 'wr_23', 'bb_9', 'kst_12', 'kst_14', 'cci_23', 'wr_22', 'rsi_15', 'cmo_15', 'roc_19', 'fi_24', 'rsv_15', 'kdjk_24', 'mfi_18', 'mfi_19', 'bb_8', 'wr_6', 'cmf_24', 'roc_21', 'cmo_12', 'wma_9', 'kdjk_8', 'cmo_17', 'trix_13', 'dpo_17', 'kdjk_12', 'rsv_17', 'kdjk_26', 'eom_13', 'kdjk_21', 'mfi_9', 'wr_24']\n",
      "9 ) 26-04-2021 14_30_29 MainThread DEBUG\\ [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 46, 47, 48, 50, 52, 54, 55, 56, 57, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 81, 83, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 109, 110, 112, 114, 115, 116, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 175, 195, 196, 197, 216, 219, 225, 226, 227, 230, 232, 237, 238, 243, 246, 259, 260, 261, 263, 265, 266, 267, 268, 270, 272, 273, 274, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 293, 295, 296, 298, 299, 300, 301, 302, 304, 305, 307, 309, 310, 311, 312, 313, 314, 315, 317, 318, 342, 343, 363, 364, 366, 367, 368, 369, 370, 372, 373, 374, 375, 377, 379, 380, 382, 383, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 398, 399, 401, 403, 404, 405, 407, 408, 410, 411, 412, 413, 414, 416, 417, 418, 419, 420, 423, 424, 426, 427, 429, 430, 431, 432, 435, 437, 438, 440, 441, 442, 443, 444, 445, 446]\n",
      "10 ) 26-04-2021 14_30_29 MainThread DEBUG\\ ../stock_history/WMT/WMT.csv has data for 2000-02-24 00:00:00 to 2020-01-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# uncomment below line of code if you want to calculate features and save dataframe\n",
    "# this script prints the path at which dataframe with calculated features is saved.\n",
    "# train.py calls the DataGenerator class to \n",
    "\n",
    "%run ./train.py WMT original\n",
    "\n",
    "# this notebook was trained on cloud compute. So use your own paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "",
    "_uuid": "",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi_6</th>\n",
       "      <th>rsi_7</th>\n",
       "      <th>rsi_8</th>\n",
       "      <th>...</th>\n",
       "      <th>eom_19</th>\n",
       "      <th>eom_20</th>\n",
       "      <th>eom_21</th>\n",
       "      <th>eom_22</th>\n",
       "      <th>eom_23</th>\n",
       "      <th>eom_24</th>\n",
       "      <th>eom_25</th>\n",
       "      <th>eom_26</th>\n",
       "      <th>volume_delta</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-02-24</td>\n",
       "      <td>47.00</td>\n",
       "      <td>47.88</td>\n",
       "      <td>43.44</td>\n",
       "      <td>47.88</td>\n",
       "      <td>33.2525</td>\n",
       "      <td>19431900</td>\n",
       "      <td>10.484813</td>\n",
       "      <td>25.636878</td>\n",
       "      <td>24.162837</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>6557500.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-25</td>\n",
       "      <td>44.31</td>\n",
       "      <td>45.31</td>\n",
       "      <td>43.63</td>\n",
       "      <td>44.50</td>\n",
       "      <td>30.9051</td>\n",
       "      <td>16908500</td>\n",
       "      <td>7.546718</td>\n",
       "      <td>7.215117</td>\n",
       "      <td>20.195163</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-2523400.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-02-28</td>\n",
       "      <td>44.56</td>\n",
       "      <td>46.94</td>\n",
       "      <td>44.56</td>\n",
       "      <td>46.19</td>\n",
       "      <td>32.0788</td>\n",
       "      <td>17836100</td>\n",
       "      <td>25.691514</td>\n",
       "      <td>17.962019</td>\n",
       "      <td>16.947352</td>\n",
       "      <td>...</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>927600.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>47.94</td>\n",
       "      <td>49.75</td>\n",
       "      <td>47.94</td>\n",
       "      <td>48.75</td>\n",
       "      <td>33.8567</td>\n",
       "      <td>17197200</td>\n",
       "      <td>53.950905</td>\n",
       "      <td>38.433319</td>\n",
       "      <td>28.473520</td>\n",
       "      <td>...</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>-638900.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>49.88</td>\n",
       "      <td>50.00</td>\n",
       "      <td>47.50</td>\n",
       "      <td>49.00</td>\n",
       "      <td>34.0303</td>\n",
       "      <td>10165800</td>\n",
       "      <td>56.298450</td>\n",
       "      <td>53.023610</td>\n",
       "      <td>37.866343</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-7031400.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp   open   high    low  close  adjusted_close    volume  \\\n",
       "0  2000-02-24  47.00  47.88  43.44  47.88         33.2525  19431900   \n",
       "1  2000-02-25  44.31  45.31  43.63  44.50         30.9051  16908500   \n",
       "2  2000-02-28  44.56  46.94  44.56  46.19         32.0788  17836100   \n",
       "3  2000-02-29  47.94  49.75  47.94  48.75         33.8567  17197200   \n",
       "4  2000-03-01  49.88  50.00  47.50  49.00         34.0303  10165800   \n",
       "\n",
       "       rsi_6      rsi_7      rsi_8  ...     eom_19     eom_20     eom_21  \\\n",
       "0  10.484813  25.636878  24.162837  ... -44.898337 -44.898337 -44.898337   \n",
       "1   7.546718   7.215117  20.195163  ... -11.823639 -11.823639 -11.823639   \n",
       "2  25.691514  17.962019  16.947352  ...  17.079967  17.079967  17.079967   \n",
       "3  53.950905  38.433319  28.473520  ...  32.574780  32.574780  32.574780   \n",
       "4  56.298450  53.023610  37.866343  ...  -2.336265  -2.336265  -2.336265   \n",
       "\n",
       "      eom_22     eom_23     eom_24     eom_25     eom_26  volume_delta  labels  \n",
       "0 -44.898337 -44.898337 -44.898337 -44.898337 -44.898337     6557500.0       2  \n",
       "1 -11.823639 -11.823639 -11.823639 -11.823639 -11.823639    -2523400.0       1  \n",
       "2  17.079967  17.079967  17.079967  17.079967  17.079967      927600.0       2  \n",
       "3  32.574780  32.574780  32.574780  32.574780  32.574780     -638900.0       2  \n",
       "4  -2.336265  -2.336265  -2.336265  -2.336265  -2.336265    -7031400.0       2  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "company_code = 'WMT'\n",
    "strategy_type = 'original'\n",
    "# use the path printed in above output cell after running stock_cnn.py. It's in below format\n",
    "df = pd.read_csv(\"../outputs/fresh_rolling_train/df_\"+company_code+\".csv\")\n",
    "df['labels'] = df['labels'].astype(np.int8)\n",
    "if 'dividend_amount' in df.columns:\n",
    "    df.drop(columns=['dividend_amount', 'split_coefficient'], inplace=True)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into Training, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features 447\n",
      "train_split = 0.7\n",
      "Shape of x, y train/cv/test (2797, 447) (2797,) (1200, 447) (1200,) (1000, 447) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "list_features = list(df.loc[:, 'open':'eom_26'].columns)\n",
    "print('Total number of features', len(list_features))\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.loc[:, 'open':'eom_26'].values, df['labels'].values, train_size=0.8, \n",
    "                                                    test_size=0.2, random_state=2, shuffle=True, stratify=df['labels'].values)\n",
    "\n",
    "# smote = RandomOverSampler(random_state=42, sampling_strategy='not majority')\n",
    "# x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "# print('Resampled dataset shape %s' % Counter(y_train))\n",
    "\n",
    "if 0.7*x_train.shape[0] < 2500:\n",
    "    train_split = 0.8\n",
    "else:\n",
    "    train_split = 0.7\n",
    "# train_split = 0.7\n",
    "print('train_split =',train_split)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, train_size=train_split, test_size=1-train_split, \n",
    "                                                random_state=2, shuffle=True, stratify=y_train)\n",
    "mm_scaler = MinMaxScaler(feature_range=(0, 1)) # or StandardScaler?\n",
    "x_train = mm_scaler.fit_transform(x_train)\n",
    "x_cv = mm_scaler.transform(x_cv)\n",
    "x_test = mm_scaler.transform(x_test)\n",
    "\n",
    "x_main = x_train.copy()\n",
    "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of total 441+ features select top 'N' features (let's include base features like close, adjusted_close etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 225  # should be a perfect square\n",
    "selection_method = 'all'\n",
    "topk = 320 if selection_method == 'all' else num_features\n",
    "# if train_split >= 0.8:\n",
    "#     topk = 400\n",
    "# else:\n",
    "#     topk = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('open', 'high', 'low', 'close', 'adjusted_close', 'volume', 'rsi_6', 'rsi_7', 'rsi_8', 'rsi_9', 'rsi_10', 'rsi_11', 'rsi_12', 'rsi_13', 'rsi_14', 'rsi_15', 'rsi_16', 'rsi_17', 'rsi_18', 'rsi_19', 'rsi_20', 'rsi_21', 'rsi_22', 'rsi_23', 'rsi_24', 'rsi_25', 'rsi_26', 'wr_6', 'wr_7', 'wr_8', 'wr_9', 'wr_10', 'wr_11', 'wr_12', 'wr_13', 'wr_14', 'wr_15', 'wr_16', 'wr_17', 'wr_18', 'wr_19', 'wr_20', 'wr_21', 'wr_22', 'wr_23', 'wr_24', 'wr_25', 'wr_26', 'mfi_6', 'mfi_7', 'mfi_8', 'mfi_9', 'mfi_10', 'mfi_11', 'mfi_12', 'mfi_13', 'mfi_14', 'mfi_15', 'mfi_16', 'mfi_17', 'mfi_18', 'mfi_19', 'mfi_20', 'mfi_21', 'mfi_22', 'mfi_23', 'mfi_24', 'mfi_25', 'mfi_26', 'roc_6', 'roc_7', 'roc_8', 'roc_9', 'roc_10', 'roc_11', 'roc_12', 'roc_13', 'roc_14', 'roc_15', 'roc_16', 'roc_17', 'roc_18', 'roc_19', 'roc_20', 'roc_21', 'roc_22', 'roc_23', 'roc_24', 'roc_25', 'roc_26', 'cmf_6', 'cmf_7', 'cmf_8', 'cmf_9', 'cmf_10', 'cmf_11', 'cmf_12', 'cmf_13', 'cmf_14', 'cmf_15', 'cmf_16', 'cmf_17', 'cmf_18', 'cmf_19', 'cmf_20', 'cmf_21', 'cmf_22', 'cmf_23', 'cmf_24', 'cmf_25', 'cmf_26', 'cmo_6', 'cmo_7', 'cmo_8', 'cmo_9', 'cmo_10', 'cmo_11', 'cmo_12', 'cmo_13', 'cmo_14', 'cmo_15', 'cmo_16', 'cmo_17', 'cmo_18', 'cmo_19', 'cmo_20', 'cmo_21', 'cmo_22', 'cmo_23', 'cmo_24', 'cmo_25', 'cmo_26', 'wma_6', 'hma_0', 'hma_1', 'hma_2', 'hma_3', 'hma_4', 'hma_6', 'trix_6', 'trix_7', 'trix_8', 'trix_9', 'trix_10', 'trix_11', 'trix_12', 'trix_13', 'trix_14', 'trix_15', 'trix_16', 'trix_17', 'trix_18', 'cci_6', 'cci_7', 'cci_8', 'cci_9', 'cci_10', 'cci_11', 'cci_12', 'cci_13', 'cci_14', 'cci_15', 'cci_16', 'cci_17', 'cci_18', 'cci_19', 'cci_20', 'cci_21', 'cci_22', 'cci_23', 'cci_24', 'cci_25', 'cci_26', 'dpo_6', 'dpo_7', 'dpo_8', 'dpo_9', 'dpo_10', 'dpo_11', 'dpo_12', 'dpo_13', 'dpo_14', 'dpo_15', 'dpo_16', 'dpo_17', 'dpo_18', 'dpo_19', 'dpo_20', 'dpo_21', 'dpo_22', 'dpo_23', 'dpo_24', 'dpo_25', 'dpo_26', 'kst_6', 'kst_7', 'kst_8', 'kst_9', 'kst_10', 'kst_11', 'kst_12', 'kst_13', 'kst_14', 'kst_15', 'kst_16', 'kst_17', 'kst_18', 'kst_19', 'kst_20', 'kst_21', 'kst_22', 'kst_23', 'kst_24', 'kst_25', 'kst_26', 'dmi_6', 'dmi_7', 'dmi_8', 'dmi_9', 'dmi_10', 'dmi_11', 'dmi_12', 'dmi_13', 'dmi_14', 'dmi_15', 'dmi_16', 'dmi_17', 'dmi_18', 'dmi_19', 'dmi_20', 'dmi_21', 'dmi_22', 'dmi_23', 'dmi_24', 'dmi_25', 'dmi_26', 'fi_6', 'fi_7', 'fi_8', 'fi_9', 'fi_10', 'fi_11', 'fi_12', 'fi_13', 'fi_14', 'fi_15', 'fi_16', 'fi_17', 'fi_18', 'fi_19', 'fi_20', 'fi_21', 'fi_22', 'fi_23', 'fi_24', 'fi_25', 'fi_26', 'rsv_6', 'kdjk_6', 'rsv_7', 'kdjk_7', 'rsv_8', 'kdjk_8', 'rsv_9', 'kdjk_9', 'rsv_10', 'kdjk_10', 'rsv_11', 'kdjk_11', 'rsv_12', 'kdjk_12', 'rsv_13', 'kdjk_13', 'rsv_14', 'kdjk_14', 'rsv_15', 'kdjk_15', 'rsv_16', 'kdjk_16', 'rsv_17', 'kdjk_17', 'rsv_18', 'kdjk_18', 'rsv_19', 'kdjk_19', 'rsv_20', 'kdjk_20', 'rsv_21', 'kdjk_21', 'rsv_22', 'kdjk_22', 'rsv_23', 'kdjk_23', 'rsv_24', 'kdjk_24', 'rsv_25', 'kdjk_25', 'rsv_26', 'kdjk_26', 'eom_6', 'eom_7', 'eom_8', 'eom_9', 'eom_10', 'eom_11', 'eom_12', 'eom_13', 'eom_14', 'eom_15', 'eom_16', 'eom_17', 'eom_18', 'eom_19', 'eom_20', 'eom_21', 'eom_22', 'eom_23', 'eom_24', 'eom_25', 'eom_26')\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 195 216 217 218 219 220 222 237 238 239 240 241\n",
      " 242 243 244 245 246 247 248 249 258 259 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285\n",
      " 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303\n",
      " 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321\n",
      " 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339\n",
      " 340 341 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446]\n",
      "****************************************\n",
      "320 ('high', 'low', 'close', 'adjusted_close', 'volume', 'rsi_6', 'rsi_7', 'rsi_8', 'rsi_9', 'rsi_10', 'rsi_11', 'rsi_12', 'rsi_13', 'rsi_14', 'rsi_15', 'rsi_16', 'rsi_17', 'rsi_18', 'rsi_19', 'rsi_20', 'rsi_21', 'rsi_22', 'rsi_23', 'rsi_24', 'rsi_25', 'rsi_26', 'wr_6', 'wr_7', 'wr_8', 'wr_9', 'wr_10', 'wr_11', 'wr_12', 'wr_13', 'wr_14', 'wr_15', 'wr_16', 'wr_17', 'wr_18', 'wr_19', 'wr_20', 'wr_21', 'wr_22', 'wr_23', 'wr_24', 'wr_25', 'wr_26', 'mfi_6', 'mfi_7', 'mfi_8', 'mfi_9', 'mfi_10', 'mfi_11', 'mfi_12', 'mfi_13', 'mfi_14', 'mfi_15', 'mfi_16', 'mfi_17', 'mfi_18', 'mfi_19', 'mfi_20', 'mfi_21', 'mfi_22', 'mfi_23', 'mfi_24', 'mfi_25', 'mfi_26', 'roc_6', 'roc_7', 'roc_8', 'roc_9', 'roc_10', 'roc_11', 'roc_12', 'roc_13', 'roc_14', 'roc_15', 'roc_16', 'roc_17', 'roc_18', 'roc_19', 'roc_20', 'roc_21', 'roc_22', 'roc_23', 'roc_24', 'roc_25', 'roc_26', 'cmf_6', 'cmf_7', 'cmf_8', 'cmf_9', 'cmf_10', 'cmf_11', 'cmf_12', 'cmf_13', 'cmf_14', 'cmf_15', 'cmf_16', 'cmf_18', 'cmf_19', 'cmf_20', 'cmf_21', 'cmf_22', 'cmf_23', 'cmf_24', 'cmf_25', 'cmf_26', 'cmo_6', 'cmo_7', 'cmo_8', 'cmo_9', 'cmo_10', 'cmo_11', 'cmo_12', 'cmo_13', 'cmo_14', 'cmo_15', 'cmo_16', 'cmo_17', 'cmo_18', 'cmo_19', 'cmo_20', 'cmo_21', 'cmo_22', 'cmo_23', 'cmo_24', 'cmo_25', 'cmo_26', 'close_sma_6', 'open_sma_7', 'open_sma_13', 'open_sma_14', 'wma_23', 'hma_2', 'hma_5', 'hma_7', 'hma_8', 'hma_13', 'trix_6', 'trix_8', 'trix_9', 'trix_11', 'trix_12', 'trix_17', 'trix_18', 'trix_19', 'trix_21', 'trix_22', 'trix_23', 'trix_25', 'cci_6', 'cci_7', 'cci_8', 'cci_9', 'cci_10', 'cci_11', 'cci_12', 'cci_13', 'cci_14', 'cci_15', 'cci_16', 'cci_17', 'cci_18', 'cci_19', 'cci_20', 'cci_21', 'cci_22', 'cci_23', 'cci_24', 'cci_25', 'cci_26', 'dpo_6', 'dpo_7', 'dpo_8', 'dpo_9', 'dpo_10', 'dpo_11', 'dpo_12', 'dpo_13', 'dpo_14', 'dpo_16', 'dpo_17', 'dpo_18', 'dpo_19', 'dpo_20', 'dpo_23', 'dpo_26', 'kst_6', 'kst_7', 'kst_23', 'kst_25', 'kst_26', 'dmi_6', 'dmi_7', 'dmi_8', 'dmi_9', 'dmi_10', 'dmi_11', 'dmi_12', 'dmi_13', 'dmi_14', 'dmi_15', 'dmi_16', 'dmi_17', 'dmi_18', 'dmi_19', 'dmi_20', 'dmi_21', 'dmi_22', 'dmi_23', 'dmi_24', 'dmi_25', 'dmi_26', 'bb_6', 'bb_7', 'bb_8', 'bb_9', 'bb_10', 'bb_11', 'bb_12', 'bb_13', 'bb_14', 'bb_15', 'bb_16', 'bb_17', 'bb_18', 'bb_19', 'bb_20', 'bb_21', 'bb_22', 'bb_23', 'bb_24', 'bb_25', 'bb_26', 'fi_6', 'fi_7', 'fi_8', 'fi_9', 'fi_10', 'fi_11', 'fi_12', 'fi_13', 'fi_14', 'fi_15', 'fi_16', 'fi_17', 'fi_18', 'fi_19', 'fi_20', 'fi_21', 'fi_22', 'fi_23', 'fi_24', 'fi_25', 'fi_26', 'rsv_6', 'kdjk_6', 'rsv_7', 'kdjk_7', 'rsv_8', 'kdjk_8', 'rsv_9', 'kdjk_9', 'rsv_10', 'kdjk_10', 'rsv_11', 'kdjk_11', 'rsv_12', 'kdjk_12', 'rsv_13', 'kdjk_13', 'rsv_14', 'kdjk_14', 'rsv_15', 'kdjk_15', 'rsv_16', 'kdjk_16', 'rsv_17', 'kdjk_17', 'rsv_18', 'kdjk_18', 'rsv_19', 'kdjk_19', 'rsv_20', 'kdjk_20', 'rsv_21', 'kdjk_21', 'rsv_22', 'kdjk_22', 'rsv_23', 'kdjk_23', 'rsv_24', 'kdjk_24', 'rsv_25', 'kdjk_25', 'rsv_26', 'kdjk_26', 'eom_6', 'eom_7', 'eom_8', 'eom_9', 'eom_10', 'eom_11', 'eom_12', 'eom_13', 'eom_14', 'eom_15', 'eom_16', 'eom_17', 'eom_18', 'eom_19', 'eom_20', 'eom_21', 'eom_22', 'eom_23', 'eom_24', 'eom_25', 'eom_26')\n",
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 154 160 161 212 218 221 223 224 229 237 239 240 242\n",
      " 243 248 249 250 252 253 254 256 258 259 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285\n",
      " 286 287 289 290 291 292 293 296 299 300 301 317 319 320 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
      " 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
      " 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446]\n",
      "CPU times: user 4.03 s, sys: 60.1 ms, total: 4.09 s\n",
      "Wall time: 4.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from operator import itemgetter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "if selection_method == 'anova' or selection_method == 'all':\n",
    "    select_k_best = SelectKBest(f_classif, k=topk)\n",
    "    if selection_method != 'all':\n",
    "        x_train = select_k_best.fit_transform(x_main, y_train)\n",
    "        x_cv = select_k_best.transform(x_cv)\n",
    "        x_test = select_k_best.transform(x_test)\n",
    "    else:\n",
    "        select_k_best.fit(x_main, y_train)\n",
    "    \n",
    "    selected_features_anova = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "    print(selected_features_anova)\n",
    "    print(select_k_best.get_support(indices=True))\n",
    "    print(\"****************************************\")\n",
    "    \n",
    "if selection_method == 'mutual_info' or selection_method == 'all':\n",
    "    select_k_best = SelectKBest(mutual_info_classif, k=topk)\n",
    "    if selection_method != 'all':\n",
    "        x_train = select_k_best.fit_transform(x_main, y_train)\n",
    "        x_cv = select_k_best.transform(x_cv)\n",
    "        x_test = select_k_best.transform(x_test)\n",
    "    else:\n",
    "        select_k_best.fit(x_main, y_train)\n",
    "\n",
    "    selected_features_mic = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "    print(len(selected_features_mic), selected_features_mic)\n",
    "    print(select_k_best.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common selected featues 285 ['rsv_9', 'cmf_21', 'cmf_16', 'kst_6', 'rsi_16', 'mfi_13', 'wr_17', 'cci_22', 'wr_13', 'cmf_25', 'trix_12', 'cci_16', 'rsi_6', 'rsi_13', 'dmi_25', 'roc_12', 'wr_19', 'mfi_6', 'fi_15', 'rsv_20', 'roc_14', 'rsi_18', 'roc_20', 'cmo_13', 'cci_26', 'dpo_20', 'cmo_19', 'rsi_14', 'rsv_21', 'cmf_20', 'kdjk_14', 'mfi_22', 'fi_25', 'mfi_25', 'kst_23', 'fi_20', 'eom_22', 'rsv_18', 'high', 'cci_9', 'mfi_20', 'eom_11', 'rsi_9', 'fi_17', 'fi_23', 'dmi_23', 'dpo_12', 'dmi_9', 'cci_18', 'kdjk_23', 'rsv_24', 'cci_8', 'kdjk_13', 'dmi_10', 'kdjk_9', 'kdjk_16', 'wr_9', 'mfi_8', 'dpo_11', 'fi_6', 'kdjk_11', 'cmf_6', 'eom_20', 'cmo_23', 'mfi_14', 'cmo_7', 'roc_15', 'cmf_12', 'trix_9', 'wr_8', 'kst_7', 'rsv_10', 'eom_18', 'dmi_12', 'rsi_10', 'cmf_23', 'trix_6', 'mfi_23', 'cci_20', 'rsv_19', 'adjusted_close', 'trix_18', 'rsv_16', 'rsv_26', 'cmf_7', 'cci_15', 'eom_26', 'cmo_20', 'rsi_8', 'cmo_25', 'cci_21', 'fi_16', 'dpo_26', 'kdjk_7', 'kdjk_19', 'roc_6', 'roc_16', 'cmo_22', 'roc_18', 'eom_15', 'dpo_10', 'dmi_16', 'dpo_14', 'eom_6', 'mfi_15', 'fi_13', 'fi_22', 'mfi_16', 'wr_7', 'eom_21', 'roc_11', 'dmi_8', 'fi_18', 'dpo_18', 'rsv_23', 'eom_17', 'rsi_22', 'roc_24', 'fi_11', 'rsi_7', 'kdjk_20', 'dpo_6', 'eom_25', 'rsv_7', 'rsi_12', 'rsi_23', 'cmo_18', 'dpo_7', 'rsi_11', 'wr_26', 'cmo_24', 'dmi_24', 'eom_10', 'mfi_24', 'rsv_8', 'cmo_10', 'dmi_20', 'cmf_15', 'cmf_22', 'dpo_8', 'wr_11', 'dmi_13', 'dmi_19', 'trix_8', 'fi_12', 'cmo_16', 'rsv_22', 'cmo_11', 'dmi_6', 'fi_26', 'wr_18', 'hma_2', 'dmi_7', 'roc_22', 'cmf_11', 'dmi_14', 'rsv_13', 'eom_23', 'cci_7', 'cmf_9', 'dpo_19', 'fi_7', 'eom_12', 'wr_21', 'wr_12', 'wr_10', 'trix_11', 'mfi_10', 'eom_7', 'wr_25', 'fi_10', 'rsi_26', 'rsv_11', 'eom_24', 'cmf_26', 'cci_14', 'dpo_9', 'rsi_21', 'cci_13', 'cmf_14', 'wr_20', 'cci_11', 'fi_9', 'dmi_17', 'dpo_23', 'cmo_14', 'mfi_26', 'rsi_17', 'dpo_13', 'rsv_12', 'dpo_16', 'roc_26', 'dmi_21', 'kdjk_15', 'volume', 'mfi_12', 'cmf_18', 'cmf_8', 'cmo_9', 'cmo_26', 'close', 'rsi_24', 'roc_7', 'kdjk_22', 'cmf_10', 'kdjk_10', 'roc_10', 'kdjk_25', 'roc_9', 'dmi_26', 'kdjk_17', 'rsi_25', 'roc_23', 'mfi_21', 'low', 'roc_8', 'cci_19', 'cmo_21', 'rsv_14', 'kdjk_26', 'roc_25', 'wr_15', 'fi_21', 'cmf_13', 'cci_6', 'kdjk_6', 'eom_19', 'rsi_19', 'rsv_6', 'kst_25', 'eom_8', 'dmi_22', 'fi_8', 'roc_13', 'fi_19', 'mfi_17', 'cci_25', 'cmf_19', 'mfi_11', 'roc_17', 'kst_26', 'cci_24', 'eom_9', 'wr_14', 'wr_16', 'cci_12', 'kdjk_18', 'cmo_8', 'rsv_25', 'rsi_20', 'cmo_6', 'mfi_7', 'eom_16', 'cci_10', 'dmi_11', 'fi_14', 'eom_14', 'cci_17', 'wr_23', 'dmi_15', 'trix_17', 'cci_23', 'wr_22', 'rsi_15', 'cmo_15', 'roc_19', 'fi_24', 'rsv_15', 'kdjk_24', 'mfi_18', 'mfi_19', 'wr_6', 'cmf_24', 'roc_21', 'cmo_12', 'kdjk_8', 'kdjk_12', 'cmo_17', 'rsv_17', 'dpo_17', 'dmi_18', 'eom_13', 'kdjk_21', 'mfi_9', 'wr_24']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 46, 47, 48, 50, 52, 54, 55, 56, 57, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 81, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 107, 109, 110, 112, 114, 115, 116, 118, 119, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 218, 237, 239, 240, 242, 243, 249, 258, 259, 260, 261, 263, 265, 266, 267, 268, 270, 271, 272, 273, 274, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 291, 292, 293, 296, 299, 300, 301, 317, 321, 322, 323, 324, 325, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 341, 363, 364, 366, 367, 368, 369, 370, 372, 373, 374, 375, 377, 378, 379, 380, 382, 383, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 398, 399, 400, 401, 403, 404, 405, 407, 408, 410, 411, 412, 413, 414, 416, 417, 418, 419, 420, 423, 424, 425, 426, 427, 430, 431, 432, 435, 437, 438, 440, 441, 442, 443, 444, 445, 446]\n"
     ]
    }
   ],
   "source": [
    "if selection_method == 'all':\n",
    "    common = list(set(selected_features_anova).intersection(selected_features_mic))\n",
    "    print(\"common selected featues\", len(common), common)\n",
    "    if len(common) < num_features:\n",
    "        raise Exception('number of common features found {} < {} required features. Increase \"topk variable\"'.format(len(common), num_features))\n",
    "    feat_idx = []\n",
    "    for c in common:\n",
    "        feat_idx.append(list_features.index(c))\n",
    "    feat_idx = sorted(feat_idx[0:225])\n",
    "    print(feat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x, y train/cv/test (2797, 225) (2797,) (1200, 225) (1200,) (1000, 225) (1000,)\n"
     ]
    }
   ],
   "source": [
    "if selection_method == 'all':\n",
    "    x_train = x_train[:, feat_idx]\n",
    "    x_cv = x_cv[:, feat_idx]\n",
    "    x_test = x_test[:, feat_idx]\n",
    "\n",
    "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, \n",
    "                                                             y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of class 0 = 6.399713979263496, class 1 = 6.149445834823024\n"
     ]
    }
   ],
   "source": [
    "_labels, _counts = np.unique(y_train, return_counts=True)\n",
    "print(\"percentage of class 0 = {}, class 1 = {}\".format(_counts[0]/len(y_train) * 100, _counts[1]/len(y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "def get_sample_weights(y):\n",
    "    \"\"\"\n",
    "    calculate the sample weights based on class weights. Used for models with\n",
    "    imbalanced data and one hot encoding prediction.\n",
    "\n",
    "    params:\n",
    "        y: class labels as integers\n",
    "    \"\"\"\n",
    "\n",
    "    y = y.astype(int)  # compute_class_weight needs int labels\n",
    "    class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
    "    \n",
    "    print(\"real class weights are {}\".format(class_weights), np.unique(y))\n",
    "    print(\"value_counts\", np.unique(y, return_counts=True))\n",
    "    sample_weights = y.copy().astype(float)\n",
    "    for i in np.unique(y):\n",
    "        sample_weights[sample_weights == i] = class_weights[i]  # if i == 2 else 0.8 * class_weights[i]\n",
    "        # sample_weights = np.where(sample_weights == i, class_weights[int(i)], y_)\n",
    "\n",
    "    return sample_weights\n",
    "\n",
    "def reshape_as_image(x, img_width, img_height):\n",
    "    x_temp = np.zeros((len(x), img_height, img_width))\n",
    "    for i in range(x.shape[0]):\n",
    "        # print(type(x), type(x_temp), x.shape)\n",
    "        x_temp[i] = np.reshape(x[i], (img_height, img_width))\n",
    "\n",
    "    return x_temp\n",
    "\n",
    "def f1_weighted(y_true, y_pred):\n",
    "    y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
    "    y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
    "    conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)  # can use conf_mat[0, :], tf.slice()\n",
    "    # precision = TP/TP+FP, recall = TP/TP+FN\n",
    "    rows, cols = conf_mat.get_shape()\n",
    "    size = y_true_class.get_shape()[0]\n",
    "    precision = tf.constant([0, 0, 0])  # change this to use rows/cols as size\n",
    "    recall = tf.constant([0, 0, 0])\n",
    "    class_counts = tf.constant([0, 0, 0])\n",
    "\n",
    "    def get_precision(i, conf_mat):\n",
    "        print(\"prec check\", conf_mat, conf_mat[i, i], tf.reduce_sum(conf_mat[:, i]))\n",
    "        precision[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[:, i]))\n",
    "        recall[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[i, :]))\n",
    "        tf.add(i, 1)\n",
    "        return i, conf_mat, precision, recall\n",
    "\n",
    "    def tf_count(i):\n",
    "        elements_equal_to_value = tf.equal(y_true_class, i)\n",
    "        as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "        count = tf.reduce_sum(as_ints)\n",
    "        class_counts[i].assign(count)\n",
    "        tf.add(i, 1)\n",
    "        return count\n",
    "\n",
    "    def condition(i, conf_mat):\n",
    "        return tf.less(i, 3)\n",
    "\n",
    "    i = tf.constant(3)\n",
    "    i, conf_mat = tf.while_loop(condition, get_precision, [i, conf_mat])\n",
    "\n",
    "    i = tf.constant(3)\n",
    "    c = lambda i: tf.less(i, 3)\n",
    "    b = tf_count(i)\n",
    "    tf.while_loop(c, b, [i])\n",
    "\n",
    "    weights = tf.math.divide(class_counts, size)\n",
    "    numerators = tf.math.multiply(tf.math.multiply(precision, recall), tf.constant(2))\n",
    "    denominators = tf.math.add(precision, recall)\n",
    "    f1s = tf.math.divide(numerators, denominators)\n",
    "    weighted_f1 = tf.reduce_sum(f.math.multiply(f1s, weights))\n",
    "    return weighted_f1\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    this calculates precision & recall \n",
    "    \"\"\"\n",
    "\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # mistake: y_pred of 0.3 is also considered 1\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    # y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
    "    # y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
    "    # conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)\n",
    "    # tf.Print(conf_mat, [conf_mat], \"confusion_matrix\")\n",
    "\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "get_custom_objects().update({\"f1_metric\": f1_metric, \"f1_weighted\": f1_weighted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real class weights are [5.20856611 5.42054264 0.38116653] [0 1 2]\n",
      "value_counts (array([0, 1, 2]), array([ 179,  172, 2446]))\n",
      "Test sample_weights\n",
      "[2 0 2 0 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0.38116653 5.20856611 0.38116653 5.20856611 0.38116653 0.38116653\n",
      " 0.38116653 0.38116653 0.38116653 0.38116653 5.42054264 0.38116653\n",
      " 0.38116653 5.42054264 0.38116653 0.38116653 0.38116653 0.38116653\n",
      " 0.38116653 0.38116653 0.38116653 0.38116653 0.38116653 0.38116653\n",
      " 0.38116653 0.38116653 0.38116653 0.38116653 0.38116653 0.38116653]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mymacbookpro/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1 2], y=[2 1 2 ... 2 2 2] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "sample_weights = get_sample_weights(y_train)\n",
    "print(\"Test sample_weights\")\n",
    "rand_idx = np.random.randint(0, 1000, 30)\n",
    "print(y_train[rand_idx])\n",
    "print(sample_weights[rand_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_enc = OneHotEncoder(sparse=False, categories='auto')  # , categories='auto'\n",
    "y_train = one_hot_enc.fit_transform(y_train.reshape(-1, 1))\n",
    "print(\"y_train\",y_train.shape)\n",
    "y_cv = one_hot_enc.transform(y_cv.reshape(-1, 1))\n",
    "y_test = one_hot_enc.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = int(np.sqrt(num_features))\n",
    "x_train = reshape_as_image(x_train, dim, dim)\n",
    "x_cv = reshape_as_image(x_cv, dim, dim)\n",
    "x_test = reshape_as_image(x_test, dim, dim)\n",
    "# adding a 1-dim for channels (3)\n",
    "x_train = np.stack((x_train,) * 3, axis=-1)\n",
    "x_test = np.stack((x_test,) * 3, axis=-1)\n",
    "x_cv = np.stack((x_cv,) * 3, axis=-1)\n",
    "print(\"final shape of x, y train/test {} {} {} {}\".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "columns = rows = 3\n",
    "for i in range(1, columns*rows +1):\n",
    "    index = np.random.randint(len(x_train))\n",
    "    img = x_train[index]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('image_'+str(index)+'_class_'+str(np.argmax(y_train[index])), fontsize=10)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, LeakyReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras.initializers import RandomUniform, RandomNormal\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "params = {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.2, 'conv2d_filters_1': 32, 'conv2d_kernel_size_1': 3, 'conv2d_mp_1': 0, \n",
    "                                               'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.3, \n",
    "                                               'conv2d_filters_2': 64, 'conv2d_kernel_size_2': 3, 'conv2d_mp_2': 2, 'conv2d_strides_2': 1, \n",
    "                                               'kernel_regularizer_2': 0.0, 'layers': 'two'}, \n",
    "           'dense_layers': {'dense_do_1': 0.3, 'dense_nodes_1': 128, 'kernel_regularizer_1': 0.0, 'layers': 'one'},\n",
    "           'epochs': 3000, 'lr': 0.001, 'optimizer': 'adam'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import *\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "def f1_custom(y_true, y_pred):\n",
    "    y_t = np.argmax(y_true, axis=1)\n",
    "    y_p = np.argmax(y_pred, axis=1)\n",
    "    f1_score(y_t, y_p, labels=None, average='weighted', sample_weight=None, zero_division='warn')\n",
    "\n",
    "def create_model_cnn(params):\n",
    "    model = Sequential()\n",
    "\n",
    "    print(\"Training with params {}\".format(params))\n",
    "    \n",
    "    conv2d_layer1 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_1\"],\n",
    "                           params[\"conv2d_layers\"][\"conv2d_kernel_size_1\"],\n",
    "                           strides=params[\"conv2d_layers\"][\"conv2d_strides_1\"],\n",
    "                           kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_1\"]), \n",
    "                           padding='same',activation=\"relu\", use_bias=True,\n",
    "                           kernel_initializer='glorot_uniform',\n",
    "                           input_shape=(x_train[0].shape[0],\n",
    "                                        x_train[0].shape[1], x_train[0].shape[2]))\n",
    "    model.add(conv2d_layer1)\n",
    "    if params[\"conv2d_layers\"]['conv2d_mp_1'] > 1:\n",
    "        model.add(MaxPool2D(pool_size=params[\"conv2d_layers\"]['conv2d_mp_1']))\n",
    "        \n",
    "    model.add(Dropout(params['conv2d_layers']['conv2d_do_1']))\n",
    "    if params[\"conv2d_layers\"]['layers'] == 'two':\n",
    "        conv2d_layer2 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_2\"],\n",
    "                               params[\"conv2d_layers\"][\"conv2d_kernel_size_2\"],\n",
    "                               strides=params[\"conv2d_layers\"][\"conv2d_strides_2\"],\n",
    "                               kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_2\"]),\n",
    "                               padding='same',activation=\"relu\", use_bias=True,\n",
    "                               kernel_initializer='glorot_uniform')\n",
    "        model.add(conv2d_layer2)\n",
    "        \n",
    "        if params[\"conv2d_layers\"]['conv2d_mp_2'] > 1:\n",
    "            model.add(MaxPool2D(pool_size=params[\"conv2d_layers\"]['conv2d_mp_2']))\n",
    "        \n",
    "        model.add(Dropout(params['conv2d_layers']['conv2d_do_2']))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(params['dense_layers'][\"dense_nodes_1\"], activation='relu'))\n",
    "    model.add(Dropout(params['dense_layers']['dense_do_1']))\n",
    "\n",
    "    if params['dense_layers'][\"layers\"] == 'two':\n",
    "        model.add(Dense(params['dense_layers'][\"dense_nodes_2\"], activation='relu', \n",
    "                        kernel_regularizer=params['dense_layers'][\"kernel_regularizer_1\"]))\n",
    "        model.add(Dropout(params['dense_layers']['dense_do_2']))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    if params[\"optimizer\"] == 'rmsprop':\n",
    "        optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
    "    elif params[\"optimizer\"] == 'sgd':\n",
    "        optimizer = optimizers.SGD(lr=params[\"lr\"], decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    elif params[\"optimizer\"] == 'adam':\n",
    "        optimizer = optimizers.Adam(learning_rate=params[\"lr\"], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', f1_metric])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def check_baseline(pred, y_test):\n",
    "    print(\"size of test set\", len(y_test))\n",
    "    e = np.equal(pred, y_test)\n",
    "    print(\"TP class counts\", np.unique(y_test[e], return_counts=True))\n",
    "    print(\"True class counts\", np.unique(y_test, return_counts=True))\n",
    "    print(\"Pred class counts\", np.unique(pred, return_counts=True))\n",
    "    holds = np.unique(y_test, return_counts=True)[1][2]  # number 'hold' predictions\n",
    "    print(\"baseline acc:\", (holds/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "model = create_model_cnn(params)\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
    "\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "best_model_path = os.path.join('.', 'best_model_keras')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                   patience=100, min_delta=0.0001)\n",
    "# csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'log_training_batch.log'), append=True)\n",
    "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=20, verbose=1, mode='min',\n",
    "                        min_delta=0.001, cooldown=1, min_lr=0.0001)\n",
    "mcp = ModelCheckpoint(best_model_path, monitor='val_f1_metric', verbose=1,\n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)  # val_f1_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(x_train, y_train, epochs=params['epochs'], verbose=1,\n",
    "                            batch_size=64, shuffle=True,\n",
    "                            # validation_split=0.3,\n",
    "                            validation_data=(x_cv, y_cv),\n",
    "                            callbacks=[mcp, rlp, es]\n",
    "                            , sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['f1_metric'])\n",
    "plt.plot(history.history['val_f1_metric'])\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train_loss', 'val_loss', 'f1', 'val_f1'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model(best_model_path)\n",
    "test_res = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"keras evaluate=\", test_res)\n",
    "pred = model.predict(x_test)\n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "check_baseline(pred_classes, y_test_classes)\n",
    "conf_mat = confusion_matrix(y_test_classes, pred_classes)\n",
    "print(conf_mat)\n",
    "labels = [0,1,2]\n",
    "\n",
    "f1_weighted = f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='weighted', sample_weight=None)\n",
    "print(\"F1 score (weighted)\", f1_weighted)\n",
    "print(\"F1 score (macro)\", f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='macro', sample_weight=None))\n",
    "print(\"F1 score (micro)\", f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='micro', sample_weight=None))  # weighted and micro preferred in case of imbalance\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-s-kappa --> supports multiclass; ref: https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english\n",
    "print(\"cohen's Kappa\", cohen_kappa_score(y_test_classes, pred_classes))\n",
    "\n",
    "recall = []\n",
    "for i, row in enumerate(conf_mat):\n",
    "    recall.append(np.round(row[i]/np.sum(row), 2))\n",
    "    print(\"Recall of class {} = {}\".format(i, recall[i]))\n",
    "print(\"Recall avg\", sum(recall)/len(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda uninstall pydot\n",
    "# !conda uninstall pydotplus\n",
    "# !conda uninstall graphviz\n",
    "\n",
    "!conda install pydot\n",
    "!conda install pydotplus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
